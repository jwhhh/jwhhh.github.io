---
title:  "Pattern recognition and machine learning - :notebook_with_decorative_cover:#1"
tags: books machine-learning
layout: article
---

Scope: [Bishop](https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/) 1.1-1.6

# Basic ML concepts

- a large set of N digits $\{ x_1, . . . , x_N\}$ called a ***training set*** is used to tune the parameters of an adaptive model.
- we can express the category of a digit using ***target vector t***, which represents the identity of the corresponding digit.
- the result of running the machine learning algorithm can be expressed as a function y(x) which takes a new digit image x as input and that generates an output vector y, encoded in the same way as the target vectors.
- the precise form of the function y(x) is determined during the ***training phase***, also known as ***the learning phase***, on the basis of the training data. 
- once the model is trained it can then determine the identity of new digit images, which are said to comprise a ***test set***.
- the ability to categorize correctly new examples that differ from those used for training is known as ***generalization***.

## Categories

- supervised learning: applications in which the training data comprises examples of the input vectors along with their corresponding target vectors
- unsupervised learning: other pattern recognition problems where the training data consists of a set of input vectors x without any corresponding target values
  - clustering: to discover groups of similar examples within the data
  - density estimation: to determine the distribution of data within the input space
  - visualisation: to project the data from a high-dimensional space down to two or three dimensions
- reinforcement learning: the problem of finding suitable actions to take in a given situation in order to maximize a reward

# Polynomial curve fitting

## Problem
We shall fit the data using a polynomial function of the form

$$
y(x,\mathbf{w}) = w_0 + w_1 x + w_2 x^2 + ... + w_M x^M = \sum_{j=0}^M w_j x^j
$$

where $M$ is the order of the polynomial, and $x^j$ denotes $x$ raised to the power of $j$.
The polynomial coefficients $w_0, ..., w_M$ are collectively denoted by the vector $\mathbf{w}$.

## Evaluation

***Error function*** measures the misfit between the function $y(x, \mathbf{w})$, for any given value of
$\mathbf{w}$, and the training set data points.

One simple choice is given by the sum of the squares of the errors between the predictions $y(x_n,\mathbf{w})$
for each data point $x_n$ and the corresponding target values $t_n$, so that we minimise

$$
E(\mathbf{w}) = \frac{1}{2} \sum_{n=1}^N \{y(x_n, \mathbf{w}) - t_n\}^2
$$

where 1/2 is for later convenience.

Since the error function is a quadratic function of the coefficients $\mathbf{w}$, its derivatives
with respect to the coefficients will be linear in the elements of $\mathbf{w}$, and so the minimisation
of the error function has a unique solution, denoted by $\mathbf{w^*}$, which can be found in closed form.

The problem of choosing the right order $M$ involves an important concepts called ***model comparison*** or
***model selection***.

Note that it is sometimes more convenient to use the root-mean-square (RMS) error defined by

$$
E_{RMS} = \sqrt {2E(\mathbf{w}^*)/N}
$$

### when $M$ is changed
As $M$ increases, the magnitude of the coefficients typically gets larger.

### when data size is changed
For a given model complexity, the over-fitting problem become less severe as the size of the data set increases.

Another way to say this is that: the larger the data set, the more complex (in other words more flexible) the
model that we can afford to fit to the data.

## Regularisation

One technique to control the over-fitting phenomenon is ***regularisation***, which involves adding a penalty term to
the error function in order to discourage the coefficients from reaching large values. The simplest example (sum
of squares of all of the coefficients) leads to a modified error function of the form:

$$
\tilde{E}(\mathbf{w}) = \frac{1}{2} \sum_{n=1}^N \{y(x_n, \mathbf{w}) - t_n\}^2 + \frac{\lambda}{2} ||\mathbf{w}||^2
$$

where $||\mathbf{w}||^2 = \mathbf{w}^T \mathbf{w} = w_0^2 + w_1^2 + ... + w_M^2$, and the coefficient $\lambda$ governs
the relative importance of the regularisation term compared with the sum-of-squares error term.

Techniques such as this are known in the statistics literature as ***shrinkage*** methods because they reduce the value
of the coefficients. The particular case of a quadratic regulariser is called ***ridge regression***. In the context of
neural networks, this approach is known as ***weight decay***.

# Probability theory

> Probability provides a consistent framework for the quantification and manipulation of uncertainty and forms one of
> the central foundations for pattern recognition.

## Densities

### Discrete variables
(skipping quick intro of *probability*, *sum rule*, *product rule*, *joint probability*, *marginal probability*, 
*conditional probability*, *Bayes' theorem*, *prior probability*, *posterior probability*, *independent*)

Note that if $x$ is a discrete variable, then $p(x)$ is sometimes called a ***probability mass function*** because
it can be regarded as a set of "probability masses" concentrated at the allowed values of $x$.

### Continuous variables

If a probability of a real-valued variable $x$ falling in the interval $(x, x+\delta x)$ is given by $p(x)\delta x$ for 
$\delta x \rightarrow 0$, then $p(x)$ is called the ***probability density*** over $x$.

The probability that $x$ will lie in an interval $(a,b)$ is then given by 

$$
p(x\in (a,b)) = \int_a^b p(x) dx
$$

The cummulative distribution function is defined by the probability that $x$ lies in the interval $(-\infty,z)$:

$$
P(z) = \int_{-\infty}^z p(x) dx
$$

which satisfies $P'(x) = p(x)$.

The sum and product rules of probability, as well as Bayes' theorem, apply equally to the case of probability densities,
or to combinations of discrete and continuous variables.

#### nonlinear change of variable
Under a *nonlinear change of variable*, a probability density transforms differently from a simple function, due to the
Jacobian factor. For instance, if we consider a chnage of variables $x=g(y)$, then a function $f(x)$ becomes
$\tilde{f}(y)=f(g(y))$. Now consider a probability density $p_x(x)$ that corresponds to a density $p_y(y)$ with respect
to the new variable $y$, where the suffices denote the fact that $p_x(x)$ and $p_y(y)$ are different densities.
Observations falling in the range $(x,x+\delta x)$ will, for small values of $\delta x$, be transformed into the range
$(y,y+\delta y)$ where $p_x(x)\delta x \simeq p_y(y)\delta y$, and hence

$$
p_y(y) = p_x(x)|\frac{dx}{dy}| = p_x(g(y))|g'(y)|
$$

One consequence of this property is that the concept of the maximum of a probability density is dependent on the choice 
of variable.

## E & cov

For a discrete distribution, $\mathbb{E}[f]=\sum_x p(x)f(x)$.

For a continuous distribution, $\mathbb{E}[f]=\int p(x)f(x)dx$.

In either case, if we are given a finite number $N$ of points drawn from the probability distribution or probability density,
then the expectation can be approximated as a finite sum over these points, 
$\mathbb{E}[f]\simeq \frac{1}{N}\sum_{n=1}^N f(x_n)$.

$\mathbb{E}_x[f(x,y)]$ denotes the average of the function $f(x,y)$ with respect to the distribution of $x$.
Note that this will be a function of $y$.

For *conditional expectation*, $\mathbb{E}_x[f\|y]=\sum_x p(x\|y)f(x)$ for discrete variables, 
and $\mathbb{E}_x[f\|y]=\int_x p(x\|y)f(x)$ for continuous variables.

The ***variance*** of $f(x)$ is defined by

$$
\begin{aligned}
var[f] &= \mathbb{E}[(f(x)-\mathbb[f(x)])^2] \\
&= \mathbb{E}[f(x)^2] - \mathbb{E}[f(x)]^2
\end{aligned}
$$

and provides a measure of how much variability there is in $f(x)$ around its mean value $\mathbb{E}[f(x)]$.

If we consider the variance of the variable $x$ itself, then it's $var[x]=\mathbb{E}[x^2]-\mathbb{E}[x]^2$.

For two random variables $x$ and $y$, the ***covariance*** is defined by

$$
\begin{aligned}
cov[x,y] &= \mathbb{E}_{x,y} [\{x-\mathbb{E}[x]\} \{y-\mathbb{E}[y]\}]\\
&= \mathbb{E}[xy]-\mathbb{E}[x]\mathbb{E}[y]
\end{aligned}
$$

which expresses the extent to which $x$ and $y$ vary together. If $x$ and $y$ are independent, then their covariance vanishes.

In the case of two vectors of random variables $x$ and $y$, the covariance is a matrix

$$
\begin{aligned}
cov[\mathbf{x},\mathbf{y}] &= \mathbb{E}_{\mathbf{x},\mathbf{y}} [\{\mathbf{x}-\mathbb{E}[\mathbf{x}]\} \{\mathbf{y}^T - \mathbb{E}[\mathbf{y}^T]\}]\\
&= \mathbb{E}_{\mathbf{x},\mathbf{y}} [\mathbf{x}\mathbf{y}^T] - \mathbb{E}[\mathbf{x}]\mathbb{E}[\mathbf{y}^T]
\end{aligned}
$$

## Bayesian

We refer to above as the *classical* or *frequentist* interpretation of probability. Now we turn to a more general *Bayesian* view, in which probabilities provide a quantification of uncertainty.

$$
p(\mathbf{w}|\mathcal{D}) = \frac{p(\mathcal{D}|\mathbf{w})p(\mathbf{w})}{p(\mathcal{D})}\\
\text{posterior} \propto \text{likelihood} \times \text{prior}
$$

The denominator in the Bayes' theorem is the normalisation constant, which ensures that the posterior
distribution on the left-hand side is a valid probability desntiy and integrates to one.

In both the Bayesian and frequentist paradigms, the likelihood function $p(\mathcal{D}\|\mathbf{w})$ plays a central role.
- in a *frequentist* setting, $\mathbf{w}$ is considered to be a fixed parameter, whose value is determined by some form of "estimator", and error bars on this estimate are obtained by considering the distribution of possible data sets $\mathcal{D}$.
  - a widely used frequentist estimator is ***maximum likelihood***, in which $\mathbf{w}$ is set to the value that maximises the likelihood function $p(\mathcal{D}\|\mathbf{w})$. In the ML literature, the negative log of the likelihood function is called an ***error function***.
  - one approach to determining frequentist error bars is the ***bootstrap***. The statistical accuracy of parameter estimates can be evaluated by looking at the variability of predictions between the different bootstrap data sets (subsets of the original data set that are randomly sampled for $L$ times).
- from the *Bayesian* viewpoint, there is only a single data set $\mathcal{D}$ (the one observed), and the uncertainty in the parameters is expressed through a probability distribution over $\mathbf{w}$.
  - advantage: the inclusion of prior knowledge arises naturally

There is no unique frequentist, or even Bayesian, viewpoint.

## Gaussian

The ***normal*** / ***Gaussian*** distribution for a single real-valued variable $x$

$$
\mathcal{N}(x|\mu,\sigma^2) = \frac{1}{(2\pi\sigma^2)^{\frac{1}{2}}} exp\{-\frac{1}{2\sigma^2}(x-\mu)^2\}
$$

is governed by 2 parameters, $\mu$ called ***mean*** and $\sigma^2$ called the ***variance***. Moreover, the
square root of the variance given by $\sigma$ is called the ***standard deviation***, and the reciprocal of the variance written as $\beta=\frac{1}{\sigma^2}$ is called the ***precision***.

The Gaussian distribution defined over a $D$-dimensional vector $\mathbf{x}$ of continuous variables is given
by

$$
\mathcal{N}(\mathbf{x}|\mathbf{\mu},\mathbf{\Sigma}) = 
\frac{1}{(2\pi)^{\frac{D}{2}}} \frac{1}{|\mathbf{\Sigma}|^{\frac{1}{2}}}
exp\{-\frac{1}{2}(\mathbf{x}-\mathbf{\mu})^T \mathbf{\Sigma}^{-1}(\mathbf{x}-\mathbf{\mu})\}
$$

where the $D$-dimensional vector $\mathbf{\mu}$ is called the mean, the $D\times D$ matrix $\mathbf{\Sigma}$ 
is called the covariance, and $|\mathbf{\Sigma}|$ denotes the determinant of $\mathbf{\Sigma}$.

### maximum likelihood approach

We shall determine values for the unknown parameters $\mu$ and $\sigma^2$ in the Gaussian by maximizing the
likelihood function. In practice, it's more convenient to maximise the log of the likelihood function.

$$
\ln p(\mathbf{X}|\mu,\sigma^2) = -\frac{1}{2\sigma^2} \sum_{n=1}^N (x_N-\mu)^2-\frac{N}{2}\ln\sigma^2-
\frac{N}{2}\ln(2\pi)
$$

Maximising log likelihood above with respect with $\mu$ and $\sigma^2$, we obtain the solution given by

$$
\mu_{ML} = \frac{1}{N}\sum_{n=1}^N x_n\\
\sigma_{ML}^2 = \frac{1}{N}\sum_{n=1}^N (x_n-\mu_{ML})^2
$$

Note that $\sigma_{ML}^2$ is the ***sample variance*** measured with respect to the sample mean $\mu_{ML}$.

*Limitations*: the maximum likelihood approach systematically underestimates the variance of the 
distribution. This is an example of a phenomenon called ***bias*** and is related to the problem of 
 over-fitting.
